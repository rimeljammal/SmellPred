{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import packages"
      ],
      "metadata": {
        "id": "gjy4yMe9Onlp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "-GqLfkBff5kH"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import StackingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import f1_score, matthews_corrcoef, balanced_accuracy_score, recall_score, precision_score, accuracy_score, roc_auc_score\n",
        "\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from lightgbm import LGBMClassifier\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read data and split"
      ],
      "metadata": {
        "id": "A5y6ZMIMOvpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(filename):\n",
        "\n",
        "    data=pd.read_csv(filename)\n",
        "    features=data.drop(['fe'], axis='columns')\n",
        "    label=data['fe']\n",
        "\n",
        "    test_features=features.values.reshape(-1,61)\n",
        "    test_label=label.values.reshape(-1,1)\n",
        "\n",
        "    return test_features, test_label.ravel()"
      ],
      "metadata": {
        "id": "l67UOBRLf-Na"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AutoML Feature engineering"
      ],
      "metadata": {
        "id": "RkitnzSTQP-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove irrelevant features and select important features\n",
        "def Feature_Importance(df):\n",
        "  print('Step: Running Feature_Importance')\n",
        "  labels = df['fe'].values\n",
        "  features = df.drop(['fe'],axis=1).values\n",
        "  feature_names = list(df.drop(['fe'],axis=1).columns)\n",
        "  print(feature_names)\n",
        "\n",
        "  model = lgb.LGBMRegressor(verbose = -1)\n",
        "  model.fit(features, labels)\n",
        "\n",
        "  feature_importances = pd.DataFrame({'feature': feature_names, 'importance': model.feature_importances_})\n",
        "  feature_importances = feature_importances.sort_values('importance', ascending = False).reset_index(drop = True)\n",
        "\n",
        "  # Normalize & sort\n",
        "  feature_importances['normalized_importance'] = feature_importances['importance'] / feature_importances['importance'].sum()\n",
        "  feature_importances['cumulative_importance'] = np.cumsum(feature_importances['normalized_importance'])\n",
        "  feature_importances = feature_importances.sort_values('cumulative_importance')\n",
        "\n",
        "  # Only keep important features with cumulative importance scores >= 90%\n",
        "  cumulative_importance=0.90\n",
        "  record_low_importance = feature_importances[feature_importances['cumulative_importance'] > cumulative_importance]\n",
        "  to_drop = list(record_low_importance['feature'])\n",
        "  print('Step: Finishing Feature_Importance, features to drop:', to_drop)\n",
        "  return to_drop"
      ],
      "metadata": {
        "id": "ESl0UgbUQTtQ"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove redundant features\n",
        "def Feature_Redundancy_Pearson(df):\n",
        "  print('Step: Running Feature_Redundancy_Pearson')\n",
        "  # Remove features with the redundancy > 90%\n",
        "  correlation_threshold=0.90\n",
        "  features = df.drop(['fe'],axis=1)\n",
        "  corr_matrix = features.corr().abs()\n",
        "\n",
        "  # Extract the upper triangle of the correlation matrix\n",
        "  upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k = 1).astype(bool))\n",
        "\n",
        "  # Find columns with correlation greater than 0.9\n",
        "  to_drop = [column for column in upper.columns if any(upper[column] > correlation_threshold)]\n",
        "  print('Step: Finishing Feature_Redundancy_Pearson, features to drop:', to_drop)\n",
        "  return to_drop"
      ],
      "metadata": {
        "id": "ztRQeCgoQV7a"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform feature engineering\n",
        "def Auto_Feature_Engineering(df):\n",
        "    print('Step: Running Auto_Feature_Engineering')\n",
        "    dropped_features = Feature_Importance(df)\n",
        "    # print(dropped_features)\n",
        "    df = df.drop(columns = dropped_features)\n",
        "\n",
        "    dropped_features = Feature_Redundancy_Pearson(df)\n",
        "    # print(dropped_features)\n",
        "    df = df.drop(columns = dropped_features)\n",
        "    print('Step: Finishing Auto_Feature_Engineering')\n",
        "    return df"
      ],
      "metadata": {
        "id": "3hBP1BlYQZWk"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ],
      "metadata": {
        "id": "FWWvuFA6ZdPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/defects_smells.csv')\n",
        "df = df.iloc[:,11:] # remove first 11 columns\n",
        "df = df.iloc[:,:-14] # remove all labels except fe\n",
        "df = Auto_Feature_Engineering(df)\n",
        "print(df.columns)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DWKoGNJZf0z",
        "outputId": "cc4c6a2b-7cc3-4dda-a897-fa7bf470bced"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: Running Auto_Feature_Engineering\n",
            "Step: Running Feature_Importance\n",
            "['CC', 'CCL', 'CCO', 'CI', 'CLC', 'CLLC', 'LDC', 'LLDC', 'LCOM5', 'NL', 'NLE', 'WMC', 'CBO', 'CBOI', 'NII', 'NOI', 'RFC', 'AD', 'CD', 'CLOC', 'DLOC', 'PDA', 'PUA', 'TCD', 'TCLOC', 'DIT', 'NOA', 'NOC', 'NOD', 'NOP', 'LLOC', 'LOC', 'NA', 'NG', 'NLA', 'NLG', 'NLM', 'NLPA', 'NLPM', 'NLS', 'NM', 'NOS', 'NPA', 'NPM', 'NS', 'TLLOC', 'TLOC', 'TNA', 'TNG', 'TNLA', 'TNLG', 'TNLM', 'TNLPA', 'TNLPM', 'TNLS', 'TNM', 'TNOS', 'TNPA', 'TNPM', 'TNS']\n",
            "Step: Finishing Feature_Importance, features to drop: ['NOA', 'NOC', 'PDA', 'LDC', 'TCLOC', 'LLDC', 'CCO', 'TNLS', 'TNLG', 'NOP', 'TNS', 'NLPA', 'TNLPA', 'NOD', 'CCL', 'CI']\n",
            "Step: Running Feature_Redundancy_Pearson\n",
            "Step: Finishing Feature_Redundancy_Pearson, features to drop: ['CLC', 'CLLC', 'RFC', 'TCD', 'LLOC', 'LOC', 'NLPM', 'NOS', 'NPA', 'NPM', 'TLLOC', 'TLOC', 'TNA', 'TNG', 'TNLA', 'TNLM', 'TNLPM', 'TNM', 'TNOS', 'TNPA', 'TNPM']\n",
            "Step: Finishing Auto_Feature_Engineering\n",
            "Index(['CC', 'LCOM5', 'NL', 'NLE', 'WMC', 'CBO', 'CBOI', 'NII', 'NOI', 'AD',\n",
            "       'CD', 'CLOC', 'DLOC', 'PUA', 'DIT', 'NA', 'NG', 'NLA', 'NLG', 'NLM',\n",
            "       'NLS', 'NM', 'NS', 'fe'],\n",
            "      dtype='object')\n",
            "         CC  LCOM5  NL  NLE  WMC  CBO  CBOI  NII  NOI        AD  ...  DIT  NA  \\\n",
            "0  0.075055      1   5    5   49    2    10   11    4  1.000000  ...    0   9   \n",
            "1  0.000000      0   0    0   11    3    16   28    3  0.750000  ...    0   6   \n",
            "2  0.000000      1   1    1   16    1   183  279    1  0.866667  ...    0   2   \n",
            "3  0.000000      0   0    0    7    1    14    7    0  1.000000  ...    0   0   \n",
            "4  0.000000      0   0    0    4    1     2    1    0  1.000000  ...    1   0   \n",
            "\n",
            "   NG  NLA  NLG  NLM  NLS  NM  NS  fe  \n",
            "0   4    9    4   15    1  15   1   0  \n",
            "1   6    6    6   11    2  11   2   0  \n",
            "2   2    2    2   14    1  14   1   0  \n",
            "3   0    0    0    7    0   7   0   0  \n",
            "4   0    0    0    4    4  11   4   0  \n",
            "\n",
            "[5 rows x 24 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read and split data"
      ],
      "metadata": {
        "id": "zPT6jH-Xf46Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = df.drop(['fe'],axis=1), df['fe']\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y, train_size = 0.3, shuffle=True,random_state = 42, stratify=y)"
      ],
      "metadata": {
        "id": "_vORlzKEp8CS"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Techniques"
      ],
      "metadata": {
        "id": "cvbGxgikkvcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random forest params"
      ],
      "metadata": {
        "id": "b8DswCkhtVAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the objective function\n",
        "def objective(params):\n",
        "    params = {\n",
        "        \"n_estimators\": int(params['n_estimators']),\n",
        "        \"max_depth\": int(params['max_depth']),\n",
        "        \"max_features\": int(params['max_features']),\n",
        "        \"min_samples_split\":int(params['min_samples_split']),\n",
        "        \"min_samples_leaf\":int(params['min_samples_leaf']),\n",
        "        \"criterion\":str(params['criterion'])\n",
        "    }\n",
        "    model = RandomForestClassifier( **params)\n",
        "    accuracy = cross_val_score(model, Xtrain, ytrain, scoring='matthews_corrcoef', cv=StratifiedKFold(n_splits=3)).mean()\n",
        "    return {'loss':-accuracy, 'status': STATUS_OK }\n",
        "\n",
        "# Define the hyperparameter configuration space\n",
        "space = {\n",
        "    \"n_estimators\": hp.quniform('n_estimators', 10, 100, 1),\n",
        "    \"max_depth\": hp.quniform('max_depth', 5, 50, 1),\n",
        "    \"max_features\":hp.quniform('max_features', 1, 64, 1),\n",
        "    \"min_samples_split\":hp.quniform('min_samples_split',2,11,1),\n",
        "    \"min_samples_leaf\":hp.quniform('min_samples_leaf',1,11,1),\n",
        "    \"criterion\":hp.choice('criterion',['gini','entropy'])\n",
        "}\n",
        "\n",
        "best = fmin(fn=objective,\n",
        "            space=space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=20)\n",
        "print(\"RF: Hyperopt estimated optimum {}\".format(best))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhzyRDPIjlYU",
        "outputId": "c2d63f6e-ff90-45b5-b831-46feae233e39"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 20/20 [00:59<00:00,  2.98s/trial, best loss: -0.6509108367182556]\n",
            "RF: Hyperopt estimated optimum {'criterion': 1, 'max_depth': 43.0, 'max_features': 9.0, 'min_samples_leaf': 4.0, 'min_samples_split': 3.0, 'n_estimators': 94.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = {0: 'gini', 1: 'entropy'}\n",
        "trainedRF = RandomForestClassifier(criterion = criterion[best['criterion']],max_depth = int(best['max_depth']), max_features = int(best['max_features']),\n",
        "                                   n_estimators = int(best['n_estimators']), min_samples_leaf = int(best['min_samples_leaf']), min_samples_split = int(best['min_samples_split'])\n",
        "                                   ).fit(Xtrain, ytrain)\n",
        "y_pred = trainedRF.predict(Xtest)\n",
        "\n",
        "f1 = f1_score(ytest, y_pred)\n",
        "mcc = matthews_corrcoef(ytest, y_pred)\n",
        "recall = recall_score(ytest, y_pred)\n",
        "precision = precision_score(ytest, y_pred)\n",
        "accuracy = accuracy_score(ytest, y_pred)\n",
        "auc = roc_auc_score(ytest, y_pred)\n",
        "balanced_accuracy = balanced_accuracy_score(ytest, y_pred)\n",
        "\n",
        "print(f\"F1 score: {f1}\")\n",
        "print(f\"MCC: {mcc}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"AUC: {auc}\")\n",
        "print(f\"Balanced Accuracy: {balanced_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYWUI3mIgRPz",
        "outputId": "26a63152-a5c0-416f-e1dc-56f554f901fd"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score: 0.7782469609724888\n",
            "MCC: 0.6879041515654386\n",
            "Recall: 0.7480934809348093\n",
            "Precision: 0.8109333333333333\n",
            "Accuracy: 0.8702844311377246\n",
            "AUC: 0.8359079561747741\n",
            "Balanced Accuracy: 0.8359079561747742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN params"
      ],
      "metadata": {
        "id": "er2dOGmxtcpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "space = {'n_neighbors': hp.choice('n_neighbors', np.arange(1, 10+1, dtype=int)), 'metric': hp.choice('metric',['euclidean', 'manhattan']), 'weights': hp.choice('weights',['uniform', 'distance'])}\n",
        "\n",
        "def objective(space):\n",
        "    model = KNeighborsClassifier(n_neighbors=space[\"n_neighbors\"], weights=space[\"weights\"], metric=space[\"metric\"])\n",
        "    accuracy = cross_val_score(model, Xtrain, ytrain, cv = 3).mean()\n",
        "    return {'loss': -accuracy, 'status': STATUS_OK }\n",
        "\n",
        "trials = Trials()\n",
        "best = fmin(fn= objective,\n",
        "            space= space,\n",
        "            algo= tpe.suggest,\n",
        "            max_evals = 10,\n",
        "            trials= trials)\n",
        "best"
      ],
      "metadata": {
        "id": "S3EiUR_CgFam",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "760faaa7-43e2-441b-aaba-6e6329eed42a"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 10/10 [00:04<00:00,  2.42trial/s, best loss: -0.8321394226985418]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'metric': 1, 'n_neighbors': 9, 'weights': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric = {0: 'euclidean', 1: 'manhattan'}\n",
        "weights = {0: 'uniform', 1: 'distance'}\n",
        "n_neighbors = {0:1, 1:2, 2:3, 3:4, 4:5, 5:6, 6:7, 7:8, 8:9, 9:10}\n",
        "\n",
        "trainedKNN = KNeighborsClassifier(n_neighbors = n_neighbors[best['n_neighbors']], weights = weights[best['weights']], metric = metric[best['metric']]).fit(Xtrain, ytrain)\n",
        "y_pred = trainedKNN.predict(Xtest)\n",
        "\n",
        "f1 = f1_score(ytest, y_pred)\n",
        "mcc = matthews_corrcoef(ytest, y_pred)\n",
        "recall = recall_score(ytest, y_pred)\n",
        "precision = precision_score(ytest, y_pred)\n",
        "accuracy = accuracy_score(ytest, y_pred)\n",
        "auc = roc_auc_score(ytest, y_pred)\n",
        "balanced_accuracy = balanced_accuracy_score(ytest, y_pred)\n",
        "\n",
        "print(f\"F1 score: {f1}\")\n",
        "print(f\"MCC: {mcc}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"AUC: {auc}\")\n",
        "print(f\"Balanced Accuracy: {balanced_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oYVXWJXslYQ",
        "outputId": "d1612bce-8fec-456b-caf7-01a8e8442804"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score: 0.7379255740300871\n",
            "MCC: 0.6382354444329864\n",
            "Recall: 0.6878228782287823\n",
            "Precision: 0.7959009393680615\n",
            "Accuracy: 0.8513473053892215\n",
            "AUC: 0.8053423159298835\n",
            "Balanced Accuracy: 0.8053423159298834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision trees params"
      ],
      "metadata": {
        "id": "j0YkFijtg47M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the objective function\n",
        "def objective(params):\n",
        "    params = {\n",
        "        \"max_depth\": int(params['max_depth']),\n",
        "        \"max_features\": int(params['max_features']),\n",
        "        \"min_samples_split\":int(params['min_samples_split']),\n",
        "        \"min_samples_leaf\":int(params['min_samples_leaf']),\n",
        "        \"criterion\":str(params['criterion'])\n",
        "    }\n",
        "    model = DecisionTreeClassifier( **params)\n",
        "    accuracy = cross_val_score(model, Xtrain, ytrain, scoring='matthews_corrcoef', cv=StratifiedKFold(n_splits=3)).mean()\n",
        "    return {'loss':-accuracy, 'status': STATUS_OK }\n",
        "\n",
        "# Define the hyperparameter configuration space\n",
        "space = {\n",
        "    \"max_depth\": hp.quniform('max_depth', 5, 50, 1),\n",
        "    \"max_features\":hp.quniform('max_features', 1, 64, 1),\n",
        "    \"min_samples_split\":hp.quniform('min_samples_split',2,11,1),\n",
        "    \"min_samples_leaf\":hp.quniform('min_samples_leaf',1,11,1),\n",
        "    \"criterion\":hp.choice('criterion',['gini','entropy'])\n",
        "}\n",
        "\n",
        "best = fmin(fn=objective,\n",
        "            space=space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=20)\n",
        "print(\"DTs: Hyperopt estimated optimum {}\".format(best))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAX5mY4vg4U_",
        "outputId": "971f09e8-d36c-4170-c7d8-46132947d5e7"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 20/20 [00:02<00:00,  7.56trial/s, best loss: -0.5649960034451268]\n",
            "DTs: Hyperopt estimated optimum {'criterion': 1, 'max_depth': 5.0, 'max_features': 36.0, 'min_samples_leaf': 10.0, 'min_samples_split': 7.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = {0: 'gini', 1: 'entropy'}\n",
        "trainedDT = DecisionTreeClassifier(criterion = criterion[best['criterion']],max_depth = int(best['max_depth']), max_features = int(best['max_features']),\n",
        "                                   min_samples_leaf = int(best['min_samples_leaf']), min_samples_split = int(best['min_samples_split'])).fit(Xtrain, ytrain)\n",
        "y_pred = trainedDT.predict(Xtest)\n",
        "\n",
        "f1 = f1_score(ytest, y_pred)\n",
        "mcc = matthews_corrcoef(ytest, y_pred)\n",
        "recall = recall_score(ytest, y_pred)\n",
        "precision = precision_score(ytest, y_pred)\n",
        "accuracy = accuracy_score(ytest, y_pred)\n",
        "auc = roc_auc_score(ytest, y_pred)\n",
        "balanced_accuracy = balanced_accuracy_score(ytest, y_pred)\n",
        "\n",
        "print(f\"F1 score: {f1}\")\n",
        "print(f\"MCC: {mcc}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"AUC: {auc}\")\n",
        "print(f\"Balanced Accuracy: {balanced_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJrpURQ2g-GS",
        "outputId": "ebc144e6-dc8d-475f-eb8b-1ecc4070a330"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score: 0.7246740220661987\n",
            "MCC: 0.6078089804554989\n",
            "Recall: 0.7109471094710947\n",
            "Precision: 0.7389414472002046\n",
            "Accuracy: 0.8356287425149701\n",
            "AUC: 0.8005515536597002\n",
            "Balanced Accuracy: 0.8005515536597001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stacking classifier"
      ],
      "metadata": {
        "id": "I-7GrXffO_b1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cls1 = ('RF', trainedRF)\n",
        "cls2 = ('DT', trainedDT)\n",
        "cls3 = ('KNN', trainedKNN)\n",
        "predictors = [cls1, cls2, cls3]\n",
        "clf = StackingClassifier(estimators=predictors, final_estimator=RandomForestClassifier())"
      ],
      "metadata": {
        "id": "3wVMb1S7sv4H"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainedCLF = clf.fit(Xtrain, ytrain)\n",
        "\n",
        "y_pred = trainedCLF.predict(Xtest)\n",
        "\n",
        "f1 = f1_score(ytest, y_pred)\n",
        "mcc = matthews_corrcoef(ytest, y_pred)\n",
        "recall = recall_score(ytest, y_pred)\n",
        "precision = precision_score(ytest, y_pred)\n",
        "accuracy = accuracy_score(ytest, y_pred)\n",
        "auc = roc_auc_score(ytest, y_pred)\n",
        "balanced_accuracy = balanced_accuracy_score(ytest, y_pred)\n",
        "\n",
        "print(f\"F1 score: {f1}\")\n",
        "print(f\"MCC: {mcc}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"AUC: {auc}\")\n",
        "print(f\"Balanced Accuracy: {balanced_accuracy}\")"
      ],
      "metadata": {
        "id": "Ub9iBQhzgCM7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e44b9946-87ab-495a-8bd3-7e442aff49ae"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score: 0.7653695018380022\n",
            "MCC: 0.6678314663326316\n",
            "Recall: 0.7426814268142682\n",
            "Precision: 0.7894874476987448\n",
            "Accuracy: 0.8614520958083832\n",
            "AUC: 0.8280378624119754\n",
            "Balanced Accuracy: 0.8280378624119754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uKgv2qm9q7KN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}